{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "seventh-wales",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-20T03:09:13.089188Z",
     "iopub.status.busy": "2021-03-20T03:09:13.088358Z",
     "iopub.status.idle": "2021-03-20T03:09:14.343042Z",
     "shell.execute_reply": "2021-03-20T03:09:14.342460Z",
     "shell.execute_reply.started": "2021-03-20T03:09:13.089188Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "db = pymysql.connect(host = 'localhost',user = 'root',password = '123456',db = 'zeddhzm',charset='utf8')   \n",
    "cur = db.cursor()   \n",
    "sql = \"SELECT * FROM jdcomment_new_2_classified\"\n",
    "cur.execute(sql)\n",
    "result = cur.fetchall()\n",
    "df = pd.DataFrame(list(result),columns=['ID','NICKNAME','CONTENT','CONTENT_LENGTH','CREATIONTIME','SCORE','REPLYCOUNT','IMAGESTATUS','IMAGECOUNT','USEFULVOTECOUNT','date','date_now','time_delta','COMPLETENESS','whether_useful'])\n",
    "cur.close()\n",
    "db.close()\n",
    "\n",
    "dff = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-helen",
   "metadata": {},
   "source": [
    "## 主观性计算规则\n",
    "1. 文本分句\n",
    "2. 计算每个句子的主观性\n",
    "3. 每个句子主观性计算方式:  主观线索词*主观线索词权重，做加权累加和平均\n",
    "4. 每个句子主观性求平均\n",
    "5. 输出文本主观性\n",
    "\n",
    "https://github.com/liuhuanyong/ZhuguanDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accessible-negotiation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-20T03:19:24.679700Z",
     "iopub.status.busy": "2021-03-20T03:19:24.678774Z",
     "iopub.status.idle": "2021-03-20T03:19:24.694585Z",
     "shell.execute_reply": "2021-03-20T03:19:24.693552Z",
     "shell.execute_reply.started": "2021-03-20T03:19:24.679700Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "import os\n",
    "import re\n",
    "\n",
    "class ZhuguanDetect:\n",
    "    def __init__(self):\n",
    "        #curdir = '/'.join(os.path.abspath(__file__).split('/')[:-1])\n",
    "        curdir = 'C:/Users/Zedd/Desktop/'\n",
    "        degree_file = os.path.join(curdir, 'dict/degree_words.txt')\n",
    "        deny_file = os.path.join(curdir, 'dict/deny_words.txt')\n",
    "        qingtai_file = os.path.join(curdir, 'dict/qingtai_words.txt')\n",
    "        zhuzhang_file = os.path.join(curdir, 'dict/zhuzhang_words.txt')\n",
    "        senti_file = os.path.join(curdir, 'dict/senti_words.txt')\n",
    "        pingjia_file = os.path.join(curdir, 'dict/pingjia_words.txt')\n",
    "        rencheng_file = os.path.join(curdir, 'dict/rencheng_words.txt')\n",
    "        zhishi_file = os.path.join(curdir, 'dict/rencheng_words.txt')\n",
    "        yiwen_file = os.path.join(curdir, 'dict/yiwen_words.txt')\n",
    "        lianci_file = os.path.join(curdir, 'dict/lianci_words.txt')\n",
    "        tanci_file = os.path.join(curdir, 'dict/tanci_words.txt')\n",
    "        yuqi_file = os.path.join(curdir, 'dict/yuqi_words.txt')\n",
    "        zhuangtai_file = os.path.join(curdir, 'dict/zhuangtai_words.txt')\n",
    "        nengyuan_file = os.path.join(curdir, 'dict/nengyuan_words.txt')\n",
    "\n",
    "        self.degree_words = self.load_words(degree_file)\n",
    "        self.deny_words = self.load_words(deny_file)\n",
    "        self.qingtai_words = self.load_words(qingtai_file)\n",
    "        self.zhuzhang_words = self.load_words(zhuzhang_file)\n",
    "        self.senti_words = self.load_words(senti_file)\n",
    "        self.pingjia_words = self.load_words(pingjia_file)\n",
    "        self.rencheng_words = self.load_words(rencheng_file)\n",
    "        self.zhishi_words = self.load_words(zhishi_file)\n",
    "        self.yiwen_words = self.load_words(yiwen_file)\n",
    "        self.lianci_words = self.load_words(lianci_file)\n",
    "        self.tanci_words = self.load_words(tanci_file)\n",
    "        self.yuqi_words = self.load_words(yuqi_file)\n",
    "        self.nengyuan_words = self.load_words(nengyuan_file)\n",
    "        self.zhuangtai_words = self.load_words(zhuangtai_file)\n",
    "\n",
    "    '''构造词典'''\n",
    "    def load_words(self, file):\n",
    "        return set([i.strip() for i in open(file, encoding='utf-8') if i.strip()])\n",
    "\n",
    "    '''基于主观线索进行主观性分析'''\n",
    "    def zhuguan(self, sent):\n",
    "        scores = []\n",
    "        segs = [[w.word, w.flag] for w in pseg.cut(sent)]\n",
    "        for index, seg in enumerate(segs):\n",
    "            wd = seg[0]\n",
    "            postags = seg[1]\n",
    "            score = self.score_words(wd)\n",
    "            scores.append(score)\n",
    "        return sum(scores)/len(segs)\n",
    "\n",
    "    '''通过对主观性词语进行加权，用来计算'''\n",
    "    def score_words(self, word):\n",
    "        score = 0.0\n",
    "        if word in self.degree_words:\n",
    "            score = 0.75\n",
    "        elif word in self.deny_words:\n",
    "            score = 0.51\n",
    "        elif word in self.qingtai_words:\n",
    "            score = 0.81\n",
    "        elif word in self.rencheng_words:\n",
    "            score = 0.95\n",
    "        elif word in self.zhuzhang_words:\n",
    "            score = 0.98\n",
    "        elif word in self.senti_words:\n",
    "            score = 0.4\n",
    "        elif word in self.pingjia_words:\n",
    "            score = 0.95\n",
    "        elif word in self.zhishi_words:\n",
    "            score = 0.75\n",
    "        elif word in self.yiwen_words:\n",
    "            score = 0.9\n",
    "        elif word in self.lianci_words:\n",
    "            score = 0.88\n",
    "        elif word in self.tanci_words:\n",
    "            score = 0.75\n",
    "        elif word in self.yuqi_words:\n",
    "            score = 0.75\n",
    "        elif word in self.nengyuan_words:\n",
    "            score = 0.75\n",
    "        elif word in self.zhuangtai_words:\n",
    "            score = 0.6\n",
    "        return score\n",
    "\n",
    "    '''文章分句处理, 切分长句，冒号，分号，感叹号等做维护标识'''\n",
    "    def split_sents(self, content):\n",
    "        return [sentence for sentence in re.split(r'[？?！!。；;：:\\n\\r]', content) if sentence]\n",
    "\n",
    "    '''程序主函数'''\n",
    "    def detect(self, content):\n",
    "        sents = self.split_sents(content)\n",
    "        scores = []\n",
    "        for sent in sents:\n",
    "            sent_score = self.zhuguan(sent)\n",
    "            scores.append(sent_score)\n",
    "        return sum(scores)/len(scores)\n",
    "\n",
    "    \n",
    "'''调用class提供主观性提取接口'''    \n",
    "def subjectivity_extract(sentence):\n",
    "    handler = ZhuguanDetect()\n",
    "    score = handler.detect(sentence)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tracked-british",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-20T03:19:26.592825Z",
     "iopub.status.busy": "2021-03-20T03:19:26.592825Z",
     "iopub.status.idle": "2021-03-20T03:19:26.604916Z",
     "shell.execute_reply": "2021-03-20T03:19:26.604916Z",
     "shell.execute_reply.started": "2021-03-20T03:19:26.592825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity_extract('我喜欢你')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "promotional-pepper",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-20T03:12:32.384737Z",
     "iopub.status.busy": "2021-03-20T03:12:32.384737Z",
     "iopub.status.idle": "2021-03-20T03:12:32.443307Z",
     "shell.execute_reply": "2021-03-20T03:12:32.442368Z",
     "shell.execute_reply.started": "2021-03-20T03:12:32.384737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares Installed\\Anaconda\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dff2['subjectivity'] = dff2.CONTENT.apply(subjectivity_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vulnerable-blackjack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-20T03:12:40.564386Z",
     "iopub.status.busy": "2021-03-20T03:12:40.564386Z",
     "iopub.status.idle": "2021-03-20T03:12:40.578285Z",
     "shell.execute_reply": "2021-03-20T03:12:40.578179Z",
     "shell.execute_reply.started": "2021-03-20T03:12:40.564386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NICKNAME</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CONTENT_LENGTH</th>\n",
       "      <th>CREATIONTIME</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>REPLYCOUNT</th>\n",
       "      <th>IMAGESTATUS</th>\n",
       "      <th>IMAGECOUNT</th>\n",
       "      <th>USEFULVOTECOUNT</th>\n",
       "      <th>date</th>\n",
       "      <th>date_now</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>COMPLETENESS</th>\n",
       "      <th>whether_useful</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13872879901</td>\n",
       "      <td>j***5</td>\n",
       "      <td>机器刚到手，就发布降价信息！服了，气管接口粗糙，屏幕连个膜都没有！写的记忆14次，实际10次...</td>\n",
       "      <td>56</td>\n",
       "      <td>2020-03-04 18:21:47</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>326</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14916170593</td>\n",
       "      <td>海***行</td>\n",
       "      <td>你们这是@，知道么。用你们的血压计天天测都是120-130的，80-90的，要不是我去医院拿...</td>\n",
       "      <td>92</td>\n",
       "      <td>2020-11-16 21:01:30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12329148322</td>\n",
       "      <td>布***咔</td>\n",
       "      <td>不准，比医院用的高了11</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-02 14:39:18</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>753</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12737339981</td>\n",
       "      <td>j***z</td>\n",
       "      <td>真的垃圾啊，不到一个月，显示屏就出问题了</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-05-07 21:49:36</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14050194816</td>\n",
       "      <td>心***福</td>\n",
       "      <td>测不注意测不准就这玩意还是算了吧，根本</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-04-18 20:29:44</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID NICKNAME                                            CONTENT  \\\n",
       "0  13872879901    j***5  机器刚到手，就发布降价信息！服了，气管接口粗糙，屏幕连个膜都没有！写的记忆14次，实际10次...   \n",
       "1  14916170593    海***行  你们这是@，知道么。用你们的血压计天天测都是120-130的，80-90的，要不是我去医院拿...   \n",
       "2  12329148322    布***咔                                       不准，比医院用的高了11   \n",
       "3  12737339981    j***z                               真的垃圾啊，不到一个月，显示屏就出问题了   \n",
       "4  14050194816    心***福                                测不注意测不准就这玩意还是算了吧，根本   \n",
       "\n",
       "   CONTENT_LENGTH        CREATIONTIME  SCORE  REPLYCOUNT  IMAGESTATUS  \\\n",
       "0              56 2020-03-04 18:21:47      1          14            1   \n",
       "1              92 2020-11-16 21:01:30      1          10            0   \n",
       "2              12 2019-01-02 14:39:18      1          17            1   \n",
       "3              20 2019-05-07 21:49:36      1          10            0   \n",
       "4              19 2020-04-18 20:29:44      1          23            0   \n",
       "\n",
       "   IMAGECOUNT  USEFULVOTECOUNT        date    date_now  time_delta  \\\n",
       "0           2               47  2020-03-04  2021-01-24         326   \n",
       "1           0               10  2020-11-16  2021-01-24          69   \n",
       "2           1               30  2019-01-02  2021-01-24         753   \n",
       "3           0               39  2019-05-07  2021-01-24         628   \n",
       "4           0               66  2020-04-18  2021-01-24         281   \n",
       "\n",
       "   COMPLETENESS  whether_useful  subjectivity  \n",
       "0             4               1      0.212083  \n",
       "1             2               1      0.222458  \n",
       "2             1               1      0.150000  \n",
       "3             1               1      0.135833  \n",
       "4             0               1      0.282727  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
